[FEATURE] Write a polished README.md for GhostCue

## Context
This is a real-time conversational AI assistant with audio capture and context persistence. Rename framing from "widget-helper" to "GhostCue". Do NOT frame it as an interview cheating tool - focus on legitimate use cases.

## Create README.md in project root

Structure:

```markdown
# GhostCue

**Real-time conversational AI assistant with audio capture and context persistence.**

[One-liner: Listens to system audio, transcribes in real-time, provides AI-powered responses in a minimal stealth overlay]

## What It Does

- Captures system audio (WASAPI loopback) and transcribes speech in real-time via Deepgram
- Sends transcripts to AI (Claude or Gemini) along with your custom context
- Displays responses in a minimal, always-on-top overlay designed to stay out of the way
- Maintains conversation history for natural multi-turn exchanges
- Supports screenshot OCR for visual content

## Use Cases

- **Accessibility** - Processing aid for neurodivergent individuals during live conversations
- **Language support** - Real-time assistance for ESL speakers
- **Learning & tutoring** - Ask questions about what's being explained as you hear it
- **Technical support** - Instant reference to complex knowledge bases during calls
- **Presentations** - Live Q&A assistance with your prepared materials
- **Meeting support** - Context-aware notes and responses

## Features

- **F9** - Toggle audio recording
- **F8** - Send clipboard text
- **F10** - Retry last response
- **Esc** - Cancel
- **Screenshot queue** - Capture multiple images, send together with OCR
- **Session persistence** - Full conversation history maintained
- **Multiple AI providers** - Claude, Gemini Pro, Gemini Flash (switchable via tray)

## Requirements

- Windows 10/11
- Python 3.11+
- API keys for:
  - Deepgram (speech-to-text)
  - Anthropic (Claude) and/or Google (Gemini)

## Installation

[Standard: clone, venv, pip install -r requirements.txt, .env setup]

## Configuration

- `context.txt` - Your custom context/knowledge base the AI references
- `config.py` - Overlay appearance, timeouts, etc.

## Usage

1. Add your context/reference material to `context.txt`
2. Run `python main.py`
3. App runs in system tray
4. Press F9 to start listening, F9 again to get response
5. Response appears in overlay

## Tech Stack

- Python, PyQt6, asyncio
- WASAPI loopback audio capture
- Deepgram streaming transcription
- Anthropic/Google GenAI APIs
- Windows OCR

## License

MIT
```

Keep it clean, professional, honest about functionality without being explicit about any particular use case. Let users figure out how they want to use it.

## Code Standards

Write code that looks inevitable. Follow these constraints:

**Restraint**
- Solve it in one file if possible
- No abstractions until the third time you need them
- No classes if functions will do
- No inheritance - use composition

**Functions**
- Max 25 lines, aim for 15
- One level of nesting max
- Name describes exactly what it does: `extract_billable_hours()` not `process_data()`
- Input → transform → output. No side effects unless that's the point.

**Files**
- Max 200 lines for new files
- One clear responsibility
- If you're adding a second "system" to a file, stop and split

**No Ceremony**
- No AbstractFactory, no IServiceProvider, no Manager classes
- No code "just in case" - solve the actual problem
- Delete commented-out code, don't keep it

**Data**
- Use dataclasses or plain dicts, not classes with only __init__ and getters
- Data flows obviously - reader should predict what happens next
- No global state

The best code is code you delete. Every line is a liability.
